{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9850188,"sourceType":"datasetVersion","datasetId":6044027},{"sourceId":9856445,"sourceType":"datasetVersion","datasetId":6048616}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom transformers import ViTModel, ViTFeatureExtractor\nfrom transformers import ViTImageProcessor, ViTForImageClassification\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:11.214286Z","iopub.execute_input":"2024-11-10T00:07:11.215187Z","iopub.status.idle":"2024-11-10T00:07:11.220973Z","shell.execute_reply.started":"2024-11-10T00:07:11.215142Z","shell.execute_reply":"2024-11-10T00:07:11.219837Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"%pip install pycocotools -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:11.224795Z","iopub.execute_input":"2024-11-10T00:07:11.225095Z","iopub.status.idle":"2024-11-10T00:07:22.707478Z","shell.execute_reply.started":"2024-11-10T00:07:11.225063Z","shell.execute_reply":"2024-11-10T00:07:22.706162Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import CocoDetection\nfrom torch import nn, optim\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:22.709645Z","iopub.execute_input":"2024-11-10T00:07:22.709995Z","iopub.status.idle":"2024-11-10T00:07:22.715697Z","shell.execute_reply.started":"2024-11-10T00:07:22.709958Z","shell.execute_reply":"2024-11-10T00:07:22.714667Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# Параметры\ndata_dir = '/kaggle/input/animalscropped'\ntrain_dir = f'{data_dir}/train'\nval_dir = f'{data_dir}/valid'\nbatch_size = 8\nnum_epochs = 150\nnum_classes = 1  # Установите количество классов в вашем датасете","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:22.716795Z","iopub.execute_input":"2024-11-10T00:07:22.717058Z","iopub.status.idle":"2024-11-10T00:07:22.726852Z","shell.execute_reply.started":"2024-11-10T00:07:22.717028Z","shell.execute_reply":"2024-11-10T00:07:22.725797Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:22.729475Z","iopub.execute_input":"2024-11-10T00:07:22.729801Z","iopub.status.idle":"2024-11-10T00:07:22.740257Z","shell.execute_reply.started":"2024-11-10T00:07:22.729769Z","shell.execute_reply":"2024-11-10T00:07:22.739298Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"class CocoDataset(Dataset):\n    def __init__(self, img_dir, json_file, transform=None):\n        with open(json_file) as f:\n            self.coco_data = json.load(f)\n        self.img_dir = img_dir\n        self.transform = transform\n\n        # Создаем индекс аннотаций по id изображения для быстрого доступа\n        self.annotations_index = {}\n        for annotation in self.coco_data['annotations']:\n            image_id = annotation['image_id']\n            if image_id not in self.annotations_index:\n                self.annotations_index[image_id] = []\n            self.annotations_index[image_id].append(annotation)\n\n    def __len__(self):\n        return len(self.coco_data['images'])\n\n    def __getitem__(self, idx):\n        img_info = self.coco_data['images'][idx]\n        img_path = os.path.join(self.img_dir, img_info['file_name'])\n        image = Image.open(img_path).convert('RGB')\n\n        label = None\n        # Получаем аннотации для текущего изображения\n        if img_info['id'] in self.annotations_index:\n            annotations = self.annotations_index[img_info['id']]\n            for annotation in annotations:\n                label = 0 if annotation[\"category_id\"] == 1 else 1\n        if self.transform:\n            # image = self.transform(np.array(image))\n            # mask = self.transform(np.array(mask_image))\n            image = self.transform(image)\n        return image, torch.tensor(label).float().unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:22.741500Z","iopub.execute_input":"2024-11-10T00:07:22.742062Z","iopub.status.idle":"2024-11-10T00:07:22.753179Z","shell.execute_reply.started":"2024-11-10T00:07:22.742018Z","shell.execute_reply":"2024-11-10T00:07:22.752108Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"class ViTBinaryClassifier(nn.Module):\n    def __init__(self):\n        super(ViTBinaryClassifier, self).__init__()\n        # Загружаем предобученную модель ViT\n        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224')\n        self.processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n\n        # Добавляем линейный слой для бинарной классификации\n        self.classifier = nn.Sequential(\n            nn.Linear(self.vit.config.hidden_size, 512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        # Пропускаем входные данные через ViT\n        outputs = self.vit(x)\n        # Берем выходные данные из последнего скрытого состояния [CLS]\n        cls_output = outputs.last_hidden_state[:, 0, :]\n        # Пропускаем через классификатор\n        logits = self.classifier(cls_output)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:22.754326Z","iopub.execute_input":"2024-11-10T00:07:22.754700Z","iopub.status.idle":"2024-11-10T00:07:22.766427Z","shell.execute_reply.started":"2024-11-10T00:07:22.754659Z","shell.execute_reply":"2024-11-10T00:07:22.765575Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"# Загрузка данных COCO\ntrain_dataset = CocoDataset(train_dir, f'{train_dir}/_annotations.coco.json', transform=transform)\nval_dataset = CocoDataset(val_dir, f'{val_dir}/_annotations.coco.json', transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:22.767696Z","iopub.execute_input":"2024-11-10T00:07:22.768159Z","iopub.status.idle":"2024-11-10T00:07:22.798546Z","shell.execute_reply.started":"2024-11-10T00:07:22.768114Z","shell.execute_reply":"2024-11-10T00:07:22.797805Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"model = ViTBinaryClassifier()\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\ncriterion = nn.BCELoss() \noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:22.799581Z","iopub.execute_input":"2024-11-10T00:07:22.799872Z","iopub.status.idle":"2024-11-10T00:07:23.295341Z","shell.execute_reply.started":"2024-11-10T00:07:22.799840Z","shell.execute_reply":"2024-11-10T00:07:23.294577Z"}},"outputs":[{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"def train(model, train_loader, criterion, optimizer):\n    model.train()\n    running_loss = 0.0\n    for images, targets in train_loader:\n        images = images.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    epoch_loss = running_loss \n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n    return running_loss/len(train_loader)\n\n# Функция валидации\ndef validate(model, val_loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, targets in val_loader:\n            targets = targets.to(device)\n\n            images = images.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, targets)\n\n            running_loss += loss.item()\n            predicted = (outputs > 0.5).float()\n            total += len(targets)\n            correct += (predicted == targets).sum().item()\n\n    epoch_loss = running_loss / len(val_loader) \n    accuracy = correct / total\n    return epoch_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:23.296378Z","iopub.execute_input":"2024-11-10T00:07:23.296696Z","iopub.status.idle":"2024-11-10T00:07:23.306519Z","shell.execute_reply.started":"2024-11-10T00:07:23.296664Z","shell.execute_reply":"2024-11-10T00:07:23.305494Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"# Цикл обучения\nfor epoch in range(num_epochs):\n    train_loss = train(model, train_loader, criterion, optimizer)\n    val_loss, val_accuracy = validate(model, val_loader, criterion)\n\n    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n\nprint(\"Training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T00:07:23.309308Z","iopub.execute_input":"2024-11-10T00:07:23.309668Z","iopub.status.idle":"2024-11-10T02:45:25.031180Z","shell.execute_reply.started":"2024-11-10T00:07:23.309634Z","shell.execute_reply":"2024-11-10T02:45:25.030137Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/150], Loss: 0.6888\nEpoch 1/150, Train Loss: 0.6888, Val Loss: 0.6907, Val Accuracy: 0.6107\nEpoch [2/150], Loss: 0.6876\nEpoch 2/150, Train Loss: 0.6876, Val Loss: 0.6604, Val Accuracy: 0.6219\nEpoch [3/150], Loss: 0.6715\nEpoch 3/150, Train Loss: 0.6715, Val Loss: 0.6756, Val Accuracy: 0.6242\nEpoch [4/150], Loss: 0.6738\nEpoch 4/150, Train Loss: 0.6738, Val Loss: 0.6663, Val Accuracy: 0.6264\nEpoch [5/150], Loss: 0.6697\nEpoch 5/150, Train Loss: 0.6697, Val Loss: 0.6799, Val Accuracy: 0.6219\nEpoch [6/150], Loss: 0.6666\nEpoch 6/150, Train Loss: 0.6666, Val Loss: 0.6629, Val Accuracy: 0.6242\nEpoch [7/150], Loss: 0.6681\nEpoch 7/150, Train Loss: 0.6681, Val Loss: 0.6592, Val Accuracy: 0.6242\nEpoch [8/150], Loss: 0.6656\nEpoch 8/150, Train Loss: 0.6656, Val Loss: 0.6631, Val Accuracy: 0.6264\nEpoch [9/150], Loss: 0.6656\nEpoch 9/150, Train Loss: 0.6656, Val Loss: 0.6706, Val Accuracy: 0.6152\nEpoch [10/150], Loss: 0.6716\nEpoch 10/150, Train Loss: 0.6716, Val Loss: 0.6637, Val Accuracy: 0.6242\nEpoch [11/150], Loss: 0.6658\nEpoch 11/150, Train Loss: 0.6658, Val Loss: 0.6642, Val Accuracy: 0.6242\nEpoch [12/150], Loss: 0.6623\nEpoch 12/150, Train Loss: 0.6623, Val Loss: 0.6618, Val Accuracy: 0.6242\nEpoch [13/150], Loss: 0.6672\nEpoch 13/150, Train Loss: 0.6672, Val Loss: 0.6607, Val Accuracy: 0.6242\nEpoch [14/150], Loss: 0.6655\nEpoch 14/150, Train Loss: 0.6655, Val Loss: 0.6631, Val Accuracy: 0.6197\nEpoch [15/150], Loss: 0.6642\nEpoch 15/150, Train Loss: 0.6642, Val Loss: 0.6714, Val Accuracy: 0.6219\nEpoch [16/150], Loss: 0.6838\nEpoch 16/150, Train Loss: 0.6838, Val Loss: 0.6675, Val Accuracy: 0.6107\nEpoch [17/150], Loss: 0.6779\nEpoch 17/150, Train Loss: 0.6779, Val Loss: 0.6735, Val Accuracy: 0.6107\nEpoch [18/150], Loss: 0.6780\nEpoch 18/150, Train Loss: 0.6780, Val Loss: 0.6688, Val Accuracy: 0.6107\nEpoch [19/150], Loss: 0.6750\nEpoch 19/150, Train Loss: 0.6750, Val Loss: 0.6723, Val Accuracy: 0.6107\nEpoch [20/150], Loss: 0.6767\nEpoch 20/150, Train Loss: 0.6767, Val Loss: 0.6692, Val Accuracy: 0.6107\nEpoch [21/150], Loss: 0.6824\nEpoch 21/150, Train Loss: 0.6824, Val Loss: 0.6671, Val Accuracy: 0.6107\nEpoch [22/150], Loss: 0.6761\nEpoch 22/150, Train Loss: 0.6761, Val Loss: 0.6678, Val Accuracy: 0.6107\nEpoch [23/150], Loss: 0.6734\nEpoch 23/150, Train Loss: 0.6734, Val Loss: 0.6605, Val Accuracy: 0.6107\nEpoch [24/150], Loss: 0.6768\nEpoch 24/150, Train Loss: 0.6768, Val Loss: 0.6626, Val Accuracy: 0.6107\nEpoch [25/150], Loss: 0.6684\nEpoch 25/150, Train Loss: 0.6684, Val Loss: 0.6623, Val Accuracy: 0.6107\nEpoch [26/150], Loss: 0.6770\nEpoch 26/150, Train Loss: 0.6770, Val Loss: 0.6611, Val Accuracy: 0.6107\nEpoch [27/150], Loss: 0.6609\nEpoch 27/150, Train Loss: 0.6609, Val Loss: 0.6477, Val Accuracy: 0.6107\nEpoch [28/150], Loss: 0.6733\nEpoch 28/150, Train Loss: 0.6733, Val Loss: 0.6702, Val Accuracy: 0.6107\nEpoch [29/150], Loss: 0.6692\nEpoch 29/150, Train Loss: 0.6692, Val Loss: 0.6305, Val Accuracy: 0.6107\nEpoch [30/150], Loss: 0.6652\nEpoch 30/150, Train Loss: 0.6652, Val Loss: 0.6631, Val Accuracy: 0.6107\nEpoch [31/150], Loss: 0.6548\nEpoch 31/150, Train Loss: 0.6548, Val Loss: 0.6447, Val Accuracy: 0.6510\nEpoch [32/150], Loss: 0.6423\nEpoch 32/150, Train Loss: 0.6423, Val Loss: 0.6372, Val Accuracy: 0.6107\nEpoch [33/150], Loss: 0.6480\nEpoch 33/150, Train Loss: 0.6480, Val Loss: 0.6840, Val Accuracy: 0.5145\nEpoch [34/150], Loss: 0.6144\nEpoch 34/150, Train Loss: 0.6144, Val Loss: 0.6385, Val Accuracy: 0.6376\nEpoch [35/150], Loss: 0.6210\nEpoch 35/150, Train Loss: 0.6210, Val Loss: 0.6068, Val Accuracy: 0.6711\nEpoch [36/150], Loss: 0.6146\nEpoch 36/150, Train Loss: 0.6146, Val Loss: 0.6176, Val Accuracy: 0.6689\nEpoch [37/150], Loss: 0.6186\nEpoch 37/150, Train Loss: 0.6186, Val Loss: 0.6167, Val Accuracy: 0.6711\nEpoch [38/150], Loss: 0.6379\nEpoch 38/150, Train Loss: 0.6379, Val Loss: 0.6399, Val Accuracy: 0.6532\nEpoch [39/150], Loss: 0.6326\nEpoch 39/150, Train Loss: 0.6326, Val Loss: 0.6958, Val Accuracy: 0.5615\nEpoch [40/150], Loss: 0.6177\nEpoch 40/150, Train Loss: 0.6177, Val Loss: 0.6151, Val Accuracy: 0.6555\nEpoch [41/150], Loss: 0.6003\nEpoch 41/150, Train Loss: 0.6003, Val Loss: 0.6089, Val Accuracy: 0.6711\nEpoch [42/150], Loss: 0.6149\nEpoch 42/150, Train Loss: 0.6149, Val Loss: 0.6359, Val Accuracy: 0.6667\nEpoch [43/150], Loss: 0.6195\nEpoch 43/150, Train Loss: 0.6195, Val Loss: 0.6161, Val Accuracy: 0.6711\nEpoch [44/150], Loss: 0.5976\nEpoch 44/150, Train Loss: 0.5976, Val Loss: 0.6058, Val Accuracy: 0.6935\nEpoch [45/150], Loss: 0.6156\nEpoch 45/150, Train Loss: 0.6156, Val Loss: 0.6008, Val Accuracy: 0.6868\nEpoch [46/150], Loss: 0.5949\nEpoch 46/150, Train Loss: 0.5949, Val Loss: 0.6037, Val Accuracy: 0.6846\nEpoch [47/150], Loss: 0.5961\nEpoch 47/150, Train Loss: 0.5961, Val Loss: 0.6072, Val Accuracy: 0.6689\nEpoch [48/150], Loss: 0.6073\nEpoch 48/150, Train Loss: 0.6073, Val Loss: 0.5966, Val Accuracy: 0.6644\nEpoch [49/150], Loss: 0.5977\nEpoch 49/150, Train Loss: 0.5977, Val Loss: 0.6079, Val Accuracy: 0.6622\nEpoch [50/150], Loss: 0.6153\nEpoch 50/150, Train Loss: 0.6153, Val Loss: 0.6234, Val Accuracy: 0.6779\nEpoch [51/150], Loss: 0.6177\nEpoch 51/150, Train Loss: 0.6177, Val Loss: 0.6150, Val Accuracy: 0.6935\nEpoch [52/150], Loss: 0.6105\nEpoch 52/150, Train Loss: 0.6105, Val Loss: 0.6181, Val Accuracy: 0.6622\nEpoch [53/150], Loss: 0.6080\nEpoch 53/150, Train Loss: 0.6080, Val Loss: 0.6563, Val Accuracy: 0.6331\nEpoch [54/150], Loss: 0.5838\nEpoch 54/150, Train Loss: 0.5838, Val Loss: 0.6104, Val Accuracy: 0.6532\nEpoch [55/150], Loss: 0.5819\nEpoch 55/150, Train Loss: 0.5819, Val Loss: 0.5915, Val Accuracy: 0.7159\nEpoch [56/150], Loss: 0.5696\nEpoch 56/150, Train Loss: 0.5696, Val Loss: 0.6116, Val Accuracy: 0.6935\nEpoch [57/150], Loss: 0.5642\nEpoch 57/150, Train Loss: 0.5642, Val Loss: 0.5871, Val Accuracy: 0.7069\nEpoch [58/150], Loss: 0.5666\nEpoch 58/150, Train Loss: 0.5666, Val Loss: 0.5818, Val Accuracy: 0.6890\nEpoch [59/150], Loss: 0.5451\nEpoch 59/150, Train Loss: 0.5451, Val Loss: 0.5904, Val Accuracy: 0.6913\nEpoch [60/150], Loss: 0.5500\nEpoch 60/150, Train Loss: 0.5500, Val Loss: 0.5745, Val Accuracy: 0.7092\nEpoch [61/150], Loss: 0.5643\nEpoch 61/150, Train Loss: 0.5643, Val Loss: 0.5743, Val Accuracy: 0.7002\nEpoch [62/150], Loss: 0.5582\nEpoch 62/150, Train Loss: 0.5582, Val Loss: 0.5921, Val Accuracy: 0.6846\nEpoch [63/150], Loss: 0.5364\nEpoch 63/150, Train Loss: 0.5364, Val Loss: 0.5981, Val Accuracy: 0.7047\nEpoch [64/150], Loss: 0.5358\nEpoch 64/150, Train Loss: 0.5358, Val Loss: 0.5995, Val Accuracy: 0.7069\nEpoch [65/150], Loss: 0.5293\nEpoch 65/150, Train Loss: 0.5293, Val Loss: 0.5672, Val Accuracy: 0.7092\nEpoch [66/150], Loss: 0.5314\nEpoch 66/150, Train Loss: 0.5314, Val Loss: 0.5823, Val Accuracy: 0.7159\nEpoch [67/150], Loss: 0.5121\nEpoch 67/150, Train Loss: 0.5121, Val Loss: 0.6628, Val Accuracy: 0.6667\nEpoch [68/150], Loss: 0.5175\nEpoch 68/150, Train Loss: 0.5175, Val Loss: 0.6366, Val Accuracy: 0.6622\nEpoch [69/150], Loss: 0.5050\nEpoch 69/150, Train Loss: 0.5050, Val Loss: 0.6179, Val Accuracy: 0.7136\nEpoch [70/150], Loss: 0.5053\nEpoch 70/150, Train Loss: 0.5053, Val Loss: 0.5742, Val Accuracy: 0.7181\nEpoch [71/150], Loss: 0.5134\nEpoch 71/150, Train Loss: 0.5134, Val Loss: 0.6234, Val Accuracy: 0.6846\nEpoch [72/150], Loss: 0.5165\nEpoch 72/150, Train Loss: 0.5165, Val Loss: 0.5735, Val Accuracy: 0.7159\nEpoch [73/150], Loss: 0.5048\nEpoch 73/150, Train Loss: 0.5048, Val Loss: 0.5725, Val Accuracy: 0.7293\nEpoch [74/150], Loss: 0.4938\nEpoch 74/150, Train Loss: 0.4938, Val Loss: 0.6346, Val Accuracy: 0.6600\nEpoch [75/150], Loss: 0.4851\nEpoch 75/150, Train Loss: 0.4851, Val Loss: 0.5940, Val Accuracy: 0.7226\nEpoch [76/150], Loss: 0.4978\nEpoch 76/150, Train Loss: 0.4978, Val Loss: 0.6076, Val Accuracy: 0.7114\nEpoch [77/150], Loss: 0.5014\nEpoch 77/150, Train Loss: 0.5014, Val Loss: 0.5579, Val Accuracy: 0.7248\nEpoch [78/150], Loss: 0.4840\nEpoch 78/150, Train Loss: 0.4840, Val Loss: 0.5530, Val Accuracy: 0.7383\nEpoch [79/150], Loss: 0.4630\nEpoch 79/150, Train Loss: 0.4630, Val Loss: 0.6040, Val Accuracy: 0.7248\nEpoch [80/150], Loss: 0.4821\nEpoch 80/150, Train Loss: 0.4821, Val Loss: 0.5807, Val Accuracy: 0.7315\nEpoch [81/150], Loss: 0.4729\nEpoch 81/150, Train Loss: 0.4729, Val Loss: 0.5324, Val Accuracy: 0.7472\nEpoch [82/150], Loss: 0.4493\nEpoch 82/150, Train Loss: 0.4493, Val Loss: 0.5765, Val Accuracy: 0.7450\nEpoch [83/150], Loss: 0.4381\nEpoch 83/150, Train Loss: 0.4381, Val Loss: 0.5986, Val Accuracy: 0.7226\nEpoch [84/150], Loss: 0.4501\nEpoch 84/150, Train Loss: 0.4501, Val Loss: 0.6365, Val Accuracy: 0.7069\nEpoch [85/150], Loss: 0.4235\nEpoch 85/150, Train Loss: 0.4235, Val Loss: 0.5719, Val Accuracy: 0.7114\nEpoch [86/150], Loss: 0.4434\nEpoch 86/150, Train Loss: 0.4434, Val Loss: 0.5646, Val Accuracy: 0.7226\nEpoch [87/150], Loss: 0.4631\nEpoch 87/150, Train Loss: 0.4631, Val Loss: 0.5808, Val Accuracy: 0.7315\nEpoch [88/150], Loss: 0.4519\nEpoch 88/150, Train Loss: 0.4519, Val Loss: 0.6234, Val Accuracy: 0.7136\nEpoch [89/150], Loss: 0.4462\nEpoch 89/150, Train Loss: 0.4462, Val Loss: 0.6145, Val Accuracy: 0.7405\nEpoch [90/150], Loss: 0.4526\nEpoch 90/150, Train Loss: 0.4526, Val Loss: 0.6034, Val Accuracy: 0.7427\nEpoch [91/150], Loss: 0.4353\nEpoch 91/150, Train Loss: 0.4353, Val Loss: 0.6388, Val Accuracy: 0.6644\nEpoch [92/150], Loss: 0.4357\nEpoch 92/150, Train Loss: 0.4357, Val Loss: 0.7262, Val Accuracy: 0.6846\nEpoch [93/150], Loss: 0.4727\nEpoch 93/150, Train Loss: 0.4727, Val Loss: 0.5705, Val Accuracy: 0.7002\nEpoch [94/150], Loss: 0.5244\nEpoch 94/150, Train Loss: 0.5244, Val Loss: 0.5550, Val Accuracy: 0.7204\nEpoch [95/150], Loss: 0.4897\nEpoch 95/150, Train Loss: 0.4897, Val Loss: 0.5712, Val Accuracy: 0.6846\nEpoch [96/150], Loss: 0.4582\nEpoch 96/150, Train Loss: 0.4582, Val Loss: 0.6402, Val Accuracy: 0.6846\nEpoch [97/150], Loss: 0.4249\nEpoch 97/150, Train Loss: 0.4249, Val Loss: 0.6188, Val Accuracy: 0.7271\nEpoch [98/150], Loss: 0.4234\nEpoch 98/150, Train Loss: 0.4234, Val Loss: 0.6925, Val Accuracy: 0.6779\nEpoch [99/150], Loss: 0.4764\nEpoch 99/150, Train Loss: 0.4764, Val Loss: 0.5932, Val Accuracy: 0.7069\nEpoch [100/150], Loss: 0.5264\nEpoch 100/150, Train Loss: 0.5264, Val Loss: 0.6118, Val Accuracy: 0.7159\nEpoch [101/150], Loss: 0.5091\nEpoch 101/150, Train Loss: 0.5091, Val Loss: 0.6293, Val Accuracy: 0.7226\nEpoch [102/150], Loss: 0.4953\nEpoch 102/150, Train Loss: 0.4953, Val Loss: 0.5891, Val Accuracy: 0.7002\nEpoch [103/150], Loss: 0.4698\nEpoch 103/150, Train Loss: 0.4698, Val Loss: 0.6024, Val Accuracy: 0.7159\nEpoch [104/150], Loss: 0.4504\nEpoch 104/150, Train Loss: 0.4504, Val Loss: 0.6286, Val Accuracy: 0.6935\nEpoch [105/150], Loss: 0.4451\nEpoch 105/150, Train Loss: 0.4451, Val Loss: 0.6276, Val Accuracy: 0.7002\nEpoch [106/150], Loss: 0.4305\nEpoch 106/150, Train Loss: 0.4305, Val Loss: 0.5921, Val Accuracy: 0.7159\nEpoch [107/150], Loss: 0.4193\nEpoch 107/150, Train Loss: 0.4193, Val Loss: 0.6813, Val Accuracy: 0.6980\nEpoch [108/150], Loss: 0.4077\nEpoch 108/150, Train Loss: 0.4077, Val Loss: 0.6942, Val Accuracy: 0.6779\nEpoch [109/150], Loss: 0.4006\nEpoch 109/150, Train Loss: 0.4006, Val Loss: 0.6751, Val Accuracy: 0.7226\nEpoch [110/150], Loss: 0.3996\nEpoch 110/150, Train Loss: 0.3996, Val Loss: 0.7329, Val Accuracy: 0.6555\nEpoch [111/150], Loss: 0.3884\nEpoch 111/150, Train Loss: 0.3884, Val Loss: 0.6065, Val Accuracy: 0.7360\nEpoch [112/150], Loss: 0.3854\nEpoch 112/150, Train Loss: 0.3854, Val Loss: 0.6311, Val Accuracy: 0.7159\nEpoch [113/150], Loss: 0.3970\nEpoch 113/150, Train Loss: 0.3970, Val Loss: 0.6344, Val Accuracy: 0.7092\nEpoch [114/150], Loss: 0.4217\nEpoch 114/150, Train Loss: 0.4217, Val Loss: 0.6580, Val Accuracy: 0.6980\nEpoch [115/150], Loss: 0.3942\nEpoch 115/150, Train Loss: 0.3942, Val Loss: 0.7291, Val Accuracy: 0.7047\nEpoch [116/150], Loss: 0.3986\nEpoch 116/150, Train Loss: 0.3986, Val Loss: 0.6072, Val Accuracy: 0.7069\nEpoch [117/150], Loss: 0.4134\nEpoch 117/150, Train Loss: 0.4134, Val Loss: 0.6400, Val Accuracy: 0.6980\nEpoch [118/150], Loss: 0.4382\nEpoch 118/150, Train Loss: 0.4382, Val Loss: 0.6929, Val Accuracy: 0.6935\nEpoch [119/150], Loss: 0.3934\nEpoch 119/150, Train Loss: 0.3934, Val Loss: 0.6381, Val Accuracy: 0.6980\nEpoch [120/150], Loss: 0.3900\nEpoch 120/150, Train Loss: 0.3900, Val Loss: 0.6430, Val Accuracy: 0.6779\nEpoch [121/150], Loss: 0.4036\nEpoch 121/150, Train Loss: 0.4036, Val Loss: 0.6579, Val Accuracy: 0.6577\nEpoch [122/150], Loss: 0.4036\nEpoch 122/150, Train Loss: 0.4036, Val Loss: 0.5964, Val Accuracy: 0.7025\nEpoch [123/150], Loss: 0.3866\nEpoch 123/150, Train Loss: 0.3866, Val Loss: 0.6666, Val Accuracy: 0.6868\nEpoch [124/150], Loss: 0.3684\nEpoch 124/150, Train Loss: 0.3684, Val Loss: 0.6900, Val Accuracy: 0.6846\nEpoch [125/150], Loss: 0.3878\nEpoch 125/150, Train Loss: 0.3878, Val Loss: 0.6465, Val Accuracy: 0.6890\nEpoch [126/150], Loss: 0.3742\nEpoch 126/150, Train Loss: 0.3742, Val Loss: 0.6308, Val Accuracy: 0.6644\nEpoch [127/150], Loss: 0.3824\nEpoch 127/150, Train Loss: 0.3824, Val Loss: 0.6219, Val Accuracy: 0.6846\nEpoch [128/150], Loss: 0.3685\nEpoch 128/150, Train Loss: 0.3685, Val Loss: 0.8490, Val Accuracy: 0.6421\nEpoch [129/150], Loss: 0.3711\nEpoch 129/150, Train Loss: 0.3711, Val Loss: 0.6839, Val Accuracy: 0.7069\nEpoch [130/150], Loss: 0.3573\nEpoch 130/150, Train Loss: 0.3573, Val Loss: 0.6791, Val Accuracy: 0.6622\nEpoch [131/150], Loss: 0.3226\nEpoch 131/150, Train Loss: 0.3226, Val Loss: 0.6373, Val Accuracy: 0.7136\nEpoch [132/150], Loss: 0.3235\nEpoch 132/150, Train Loss: 0.3235, Val Loss: 0.8391, Val Accuracy: 0.6398\nEpoch [133/150], Loss: 0.3192\nEpoch 133/150, Train Loss: 0.3192, Val Loss: 0.6166, Val Accuracy: 0.7136\nEpoch [134/150], Loss: 0.3192\nEpoch 134/150, Train Loss: 0.3192, Val Loss: 0.6834, Val Accuracy: 0.7204\nEpoch [135/150], Loss: 0.3207\nEpoch 135/150, Train Loss: 0.3207, Val Loss: 0.7833, Val Accuracy: 0.6913\nEpoch [136/150], Loss: 0.2979\nEpoch 136/150, Train Loss: 0.2979, Val Loss: 0.8200, Val Accuracy: 0.6779\nEpoch [137/150], Loss: 0.3397\nEpoch 137/150, Train Loss: 0.3397, Val Loss: 0.6837, Val Accuracy: 0.6779\nEpoch [138/150], Loss: 0.3000\nEpoch 138/150, Train Loss: 0.3000, Val Loss: 0.6227, Val Accuracy: 0.7405\nEpoch [139/150], Loss: 0.3095\nEpoch 139/150, Train Loss: 0.3095, Val Loss: 0.7549, Val Accuracy: 0.7226\nEpoch [140/150], Loss: 0.2837\nEpoch 140/150, Train Loss: 0.2837, Val Loss: 0.9122, Val Accuracy: 0.7047\nEpoch [141/150], Loss: 0.2860\nEpoch 141/150, Train Loss: 0.2860, Val Loss: 0.6763, Val Accuracy: 0.7047\nEpoch [142/150], Loss: 0.2719\nEpoch 142/150, Train Loss: 0.2719, Val Loss: 0.6973, Val Accuracy: 0.6913\nEpoch [143/150], Loss: 0.2724\nEpoch 143/150, Train Loss: 0.2724, Val Loss: 0.7692, Val Accuracy: 0.7226\nEpoch [144/150], Loss: 0.2836\nEpoch 144/150, Train Loss: 0.2836, Val Loss: 0.8494, Val Accuracy: 0.6980\nEpoch [145/150], Loss: 0.2994\nEpoch 145/150, Train Loss: 0.2994, Val Loss: 0.6765, Val Accuracy: 0.6935\nEpoch [146/150], Loss: 0.3241\nEpoch 146/150, Train Loss: 0.3241, Val Loss: 0.7149, Val Accuracy: 0.7114\nEpoch [147/150], Loss: 0.3096\nEpoch 147/150, Train Loss: 0.3096, Val Loss: 0.7326, Val Accuracy: 0.6913\nEpoch [148/150], Loss: 0.3114\nEpoch 148/150, Train Loss: 0.3114, Val Loss: 0.7181, Val Accuracy: 0.6935\nEpoch [149/150], Loss: 0.3163\nEpoch 149/150, Train Loss: 0.3163, Val Loss: 0.7001, Val Accuracy: 0.7025\nEpoch [150/150], Loss: 0.2855\nEpoch 150/150, Train Loss: 0.2855, Val Loss: 0.9767, Val Accuracy: 0.6868\nTraining complete.\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"torch.save(model, \"/kaggle/working/saved.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T02:45:25.032938Z","iopub.execute_input":"2024-11-10T02:45:25.033398Z","iopub.status.idle":"2024-11-10T02:45:25.640184Z","shell.execute_reply.started":"2024-11-10T02:45:25.033348Z","shell.execute_reply":"2024-11-10T02:45:25.639329Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# import torch\n# from transformers import ViTModel, ViTFeatureExtractor\n# from PIL import Image\n# from tqdm import tqdm\n\n# feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n# model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n# # Устройство для вычислений\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model.to(device)\n# model.eval()\n\n# def process_images_in_directory(directory_path, csv_file_path):\n#     # Чтение CSV файла\n#     df = pd.read_csv(csv_file_path)\n#     df.columns = df.columns.str.strip()\n#     # Колонки для нового DataFrame\n#     all_embeddings = []\n#     labels = []\n\n#     for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=f\"Processing {directory_path}\"):\n#         image_filename = row['filename']\n#         label = row['good']  # Предполагается, что 'good' является целевым лейблом\n\n#         image_path = os.path.join(directory_path, image_filename)\n        \n#         # Открытие и предобработка изображения\n#         image = Image.open(image_path).convert('RGB')\n#         inputs = feature_extractor(images=image, return_tensors=\"pt\")\n        \n#         # Перемещение тензоров на устройство\n#         inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n#         # Извлечение эмбеддинга\n#         with torch.no_grad():\n#             outputs = model(**inputs)\n#             embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Среднее по всем токенам\n\n#         all_embeddings.append(embedding)\n#         labels.append(label)\n\n#     # Преобразование списка эмбеддингов в DataFrame\n#     embeddings_df = pd.DataFrame(all_embeddings)\n    \n#     # Добавление меток\n#     embeddings_df['label'] = labels\n    \n#     return embeddings_df\n\n\n# # Пути к директориям и CSV файлам\n# directories_and_csvs = [\n#     ('/kaggle/input/animalsqualitycropped/train', '/kaggle/input/animalsqualitycropped/train/_classes.csv'),\n# ]\n\n# # Обработка всех директорий и объединение результатов\n# all_dataframes = []\n\n# for directory, csv_file in directories_and_csvs:\n#     df = process_images_in_directory(directory, csv_file)\n#     all_dataframes.append(df)\n\n# # Объединение всех данных в один DataFrame\n# final_df = pd.concat(all_dataframes, ignore_index=True)\n\n# # Сохранение в CSV файл\n# final_df.to_csv('/kaggle/working/embeddings_and_labels.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T02:45:25.641452Z","iopub.execute_input":"2024-11-10T02:45:25.641778Z","iopub.status.idle":"2024-11-10T02:45:25.660727Z","shell.execute_reply.started":"2024-11-10T02:45:25.641745Z","shell.execute_reply":"2024-11-10T02:45:25.659789Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.model_selection import train_test_split\n# from catboost import CatBoostClassifier\n# from sklearn.metrics import accuracy_score\n\n# # Предположим, что у вас есть DataFrame df, содержащий эмбеддинги и целевую переменную 'target'\n# # Например, колонки 'embedding_1', 'embedding_2', ..., 'embedding_n' содержат эмбеддинги\n# # df = pd.read_csv('your_dataset_with_embeddings.csv')\n\n# # Разделяем данные на признаки (включая эмбеддинги) и целевую переменную\n# X = df.drop(columns='label')\n# y = df['label']\n\n# # Разделяем на тренировочный и тестовый наборы\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # Создаем модель CatBoost\n# model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=4, verbose=100)\n\n# # Обучаем модель\n# model.fit(X_train, y_train)\n\n# # Делаем предсказания\n# y_pred = model.predict(X_test)\n\n# # Оцениваем точность модели\n# accuracy = accuracy_score(y_test, y_pred)\n# print(f\"Accuracy: {accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T02:45:25.661916Z","iopub.execute_input":"2024-11-10T02:45:25.662214Z","iopub.status.idle":"2024-11-10T02:45:25.677189Z","shell.execute_reply.started":"2024-11-10T02:45:25.662181Z","shell.execute_reply":"2024-11-10T02:45:25.676326Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"model.save_model('/kaggle/working/catboost_model.cbm')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T02:45:25.678261Z","iopub.execute_input":"2024-11-10T02:45:25.678562Z","iopub.status.idle":"2024-11-10T02:45:25.754076Z","shell.execute_reply.started":"2024-11-10T02:45:25.678531Z","shell.execute_reply":"2024-11-10T02:45:25.752733Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/catboost_model.cbm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'ViTBinaryClassifier' object has no attribute 'save_model'"],"ename":"AttributeError","evalue":"'ViTBinaryClassifier' object has no attribute 'save_model'","output_type":"error"}],"execution_count":98}]}